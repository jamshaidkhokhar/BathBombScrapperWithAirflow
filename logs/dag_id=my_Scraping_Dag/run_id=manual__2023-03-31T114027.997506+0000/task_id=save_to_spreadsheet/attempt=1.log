[2023-03-31T16:40:40.879+0500] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: my_Scraping_Dag.save_to_spreadsheet manual__2023-03-31T11:40:27.997506+00:00 [queued]>
[2023-03-31T16:40:40.891+0500] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: my_Scraping_Dag.save_to_spreadsheet manual__2023-03-31T11:40:27.997506+00:00 [queued]>
[2023-03-31T16:40:40.892+0500] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-31T16:40:40.892+0500] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-31T16:40:40.892+0500] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-31T16:40:40.909+0500] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): save_to_spreadsheet> on 2023-03-31 11:40:27.997506+00:00
[2023-03-31T16:40:40.926+0500] {standard_task_runner.py:55} INFO - Started process 2956 to run task
[2023-03-31T16:40:40.938+0500] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'my_Scraping_Dag', 'save_to_spreadsheet', 'manual__2023-03-31T11:40:27.997506+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/AirFlow_Task.py', '--cfg-path', '/tmp/tmpr4pn6c50']
[2023-03-31T16:40:40.939+0500] {standard_task_runner.py:83} INFO - Job 71: Subtask save_to_spreadsheet
[2023-03-31T16:40:41.111+0500] {task_command.py:388} INFO - Running <TaskInstance: my_Scraping_Dag.save_to_spreadsheet manual__2023-03-31T11:40:27.997506+00:00 [running]> on host Jamshaid-PC.localdomain
[2023-03-31T16:40:41.212+0500] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=jamshaid.afzal@tmcltd.com
AIRFLOW_CTX_DAG_OWNER=jamshaid
AIRFLOW_CTX_DAG_ID=my_Scraping_Dag
AIRFLOW_CTX_TASK_ID=save_to_spreadsheet
AIRFLOW_CTX_EXECUTION_DATE=2023-03-31T11:40:27.997506+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-31T11:40:27.997506+00:00
[2023-03-31T16:40:41.215+0500] {logging_mixin.py:137} INFO - /home/jamshaid
[2023-03-31T16:40:46.065+0500] {base_job.py:243} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: disk I/O error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/jobs/base_job.py", line 215, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/session.py", line 3053, in merge
    return self._merge(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/session.py", line 3133, in _merge
    merged = self.get(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/session.py", line 2850, in get
    return self._get_impl(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/session.py", line 2972, in _get_impl
    return db_load_fn(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/orm/session.py", line 1714, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 1705, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 1572, in _execute_clauseelement
    ret = self._execute_context(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 1943, in _execute_context
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 2124, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) disk I/O error
[SQL: SELECT job.id AS job_id, job.dag_id AS job_dag_id, job.state AS job_state, job.job_type AS job_job_type, job.start_date AS job_start_date, job.end_date AS job_end_date, job.latest_heartbeat AS job_latest_heartbeat, job.executor_class AS job_executor_class, job.hostname AS job_hostname, job.unixname AS job_unixname 
FROM job 
WHERE job.id = ? AND job.job_type IN (?)]
[parameters: (71, 'LocalTaskJob')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-03-31T16:41:06.847+0500] {python.py:177} INFO - Done. Returned value was: None
[2023-03-31T16:41:06.855+0500] {taskinstance.py:1321} INFO - Marking task as SUCCESS. dag_id=my_Scraping_Dag, task_id=save_to_spreadsheet, execution_date=20230331T114027, start_date=20230331T114040, end_date=20230331T114106
[2023-03-31T16:41:06.880+0500] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-31T16:41:06.926+0500] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
